#!/usr/bin/env python3
"""
Perfect Nude Generator - Advanced inpainting with face/background preservation
Addresses all identified issues for photorealistic results
"""

import torch
import numpy as np
from PIL import Image, ImageFilter, ImageEnhance
import cv2
from diffusers import StableDiffusionInpaintPipeline, ControlNetModel, StableDiffusionControlNetInpaintPipeline
from transformers import pipeline
import mediapipe as mp
from sklearn.cluster import KMeans
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class PerfectNudeGenerator:
    """Advanced nude generator with perfect inpainting and preservation"""
    
    def __init__(self, model_id="Kernel/sd-nsfw", device="auto"):
        """Initialize with NSFW model and advanced features"""
        self.device = "cuda" if torch.cuda.is_available() and device == "auto" else "cpu"
        logger.info(f"Using device: {self.device}")
        
        # Load NSFW Stable Diffusion model
        self.pipe = StableDiffusionInpaintPipeline.from_pretrained(
            model_id,
            torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
            safety_checker=None,
            requires_safety_checker=False
        )
        
        if self.device == "cuda":
            self.pipe = self.pipe.to(self.device)
        else:
            # CPU optimizations
            self.pipe.enable_attention_slicing()
            self.pipe.enable_sequential_cpu_offload()
        
        # Initialize MediaPipe for face/pose detection
        self.mp_face = mp.solutions.face_detection
        self.mp_pose = mp.solutions.pose
        self.face_detection = self.mp_face.FaceDetection(model_selection=1, min_detection_confidence=0.5)
        self.pose_detection = self.mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5)
        
        # Initialize clothing segmentation
        self.segmentation_pipe = pipeline("image-segmentation", 
                                         model="mattmdjaga/segformer_b2_clothes")
    
    def extract_skin_tone(self, image, face_bbox=None):
        """Extract dominant skin tone from face/visible skin areas"""
        img_array = np.array(image)
        
        if face_bbox:
            # Extract from face area
            x1, y1, x2, y2 = face_bbox
            face_region = img_array[y1:y2, x1:x2]
            pixels = face_region.reshape(-1, 3)
        else:
            # Use entire image
            pixels = img_array.reshape(-1, 3)
        
        # Remove very dark/light pixels (likely not skin)
        mask = np.all((pixels > 50) & (pixels < 200), axis=1)
        skin_pixels = pixels[mask]
        
        if len(skin_pixels) == 0:
            return [139, 119, 101]  # Default skin tone
        
        # Use KMeans to find dominant skin color
        kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)
        kmeans.fit(skin_pixels)
        
        # Return the most central cluster (likely skin)
        return kmeans.cluster_centers_[0].astype(int)
    
    def detect_face_region(self, image):
        """Detect face region for preservation"""
        img_rgb = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
        results = self.face_detection.process(img_rgb)
        
        if results.detections:
            detection = results.detections[0]  # Use first/largest face
            bbox = detection.location_data.relative_bounding_box
            h, w = image.height, image.width
            
            # Convert to absolute coordinates with padding
            x1 = max(0, int((bbox.xmin - 0.1) * w))
            y1 = max(0, int((bbox.ymin - 0.1) * h))
            x2 = min(w, int((bbox.xmin + bbox.width + 0.1) * w))
            y2 = min(h, int((bbox.ymin + bbox.height + 0.1) * h))
            
            return (x1, y1, x2, y2)
        return None
    
    def create_precise_clothing_mask(self, image):
        """Create precise mask for clothing areas only"""
        # Get clothing segmentation
        segments = self.segmentation_pipe(image)
        
        # Create mask for clothing items
        mask = Image.new('L', image.size, 0)
        
        clothing_labels = [
            'shirt', 'top', 'blouse', 'dress', 'bra', 'underwear', 
            'lingerie', 'bikini', 'swimwear', 'jacket', 'coat'
        ]
        
        for segment in segments:
            label = segment['label'].lower()
            if any(cloth in label for cloth in clothing_labels):
                # Add this segment to mask
                segment_mask = segment['mask']
                mask_array = np.array(mask)
                segment_array = np.array(segment_mask)
                
                # Combine masks
                combined = np.maximum(mask_array, segment_array)
                mask = Image.fromarray(combined)
        
        # Refine mask - remove face area
        face_bbox = self.detect_face_region(image)
        if face_bbox:
            mask_array = np.array(mask)
            x1, y1, x2, y2 = face_bbox
            mask_array[y1:y2, x1:x2] = 0  # Preserve face
            mask = Image.fromarray(mask_array)
        
        # Smooth mask edges
        mask = mask.filter(ImageFilter.GaussianBlur(radius=2))
        
        return mask
    
    def analyze_lighting(self, image):
        """Analyze lighting direction and intensity"""
        img_gray = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2GRAY)
        
        # Calculate gradients to find lighting direction
        grad_x = cv2.Sobel(img_gray, cv2.CV_64F, 1, 0, ksize=3)
        grad_y = cv2.Sobel(img_gray, cv2.CV_64F, 0, 1, ksize=3)
        
        # Average gradient direction
        avg_grad_x = np.mean(grad_x)
        avg_grad_y = np.mean(grad_y)
        
        # Lighting direction (simplified)
        if avg_grad_x > 0:
            light_direction = "right"
        else:
            light_direction = "left"
        
        # Lighting intensity (brightness)
        brightness = np.mean(img_gray)
        
        return {
            'direction': light_direction,
            'intensity': brightness,
            'contrast': np.std(img_gray)
        }
    
    def generate_perfect_nude(self, image_path, output_path=None, num_inference_steps=50):
        """Generate perfect nude with advanced preservation"""
        # Load and prepare image
        image = Image.open(image_path).convert('RGB')
        original_size = image.size
        
        # Resize for processing (maintain aspect ratio)
        max_size = 512
        if max(image.size) > max_size:
            ratio = max_size / max(image.size)
            new_size = (int(image.width * ratio), int(image.height * ratio))
            image = image.resize(new_size, Image.Resampling.LANCZOS)
        
        logger.info(f"Processing image: {image.size}")
        
        # Extract skin tone from face
        face_bbox = self.detect_face_region(image)
        skin_tone = self.extract_skin_tone(image, face_bbox)
        logger.info(f"Detected skin tone: {skin_tone}")
        
        # Analyze lighting
        lighting = self.analyze_lighting(image)
        logger.info(f"Lighting analysis: {lighting}")
        
        # Create precise clothing mask
        mask = self.create_precise_clothing_mask(image)
        
        # Enhanced prompt with skin tone and lighting
        skin_hex = f"#{skin_tone[0]:02x}{skin_tone[1]:02x}{skin_tone[2]:02x}"
        
        prompt = f"""
        perfect nude female body, realistic skin texture, natural breasts, 
        skin tone {skin_hex}, {lighting['direction']} side lighting, 
        photorealistic, high quality, detailed skin, natural shadows,
        anatomically correct, beautiful nude woman, soft skin,
        professional photography, natural lighting
        """
        
        negative_prompt = """
        artificial, plastic, fake, cartoon, anime, drawing, painting,
        oversaturated, unrealistic skin, perfect symmetry, airbrushed,
        low quality, blurry, distorted, deformed, extra limbs,
        watermark, signature, text, logo
        """
        
        # Generate with advanced settings
        logger.info("Generating nude image...")
        
        generator = torch.Generator(device=self.device).manual_seed(42)
        
        result = self.pipe(
            prompt=prompt,
            negative_prompt=negative_prompt,
            image=image,
            mask_image=mask,
            num_inference_steps=num_inference_steps,
            guidance_scale=7.5,
            generator=generator,
            strength=0.8  # Preserve more of original
        ).images[0]
        
        # Post-processing for perfect results
        result = self.post_process_result(result, image, mask, skin_tone, lighting)
        
        # Resize back to original size
        if original_size != result.size:
            result = result.resize(original_size, Image.Resampling.LANCZOS)
        
        # Save result
        if output_path:
            result.save(output_path, quality=95)
            logger.info(f"Perfect nude saved to: {output_path}")
        
        return result, mask
    
    def post_process_result(self, result, original, mask, skin_tone, lighting):
        """Advanced post-processing for perfect results"""
        # Convert to arrays
        result_array = np.array(result)
        original_array = np.array(original)
        mask_array = np.array(mask) / 255.0
        
        # Color correction - match skin tones
        result_corrected = self.match_skin_tone(result_array, original_array, mask_array, skin_tone)
        
        # Lighting correction
        result_lit = self.apply_lighting_correction(result_corrected, lighting)
        
        # Texture enhancement
        result_textured = self.enhance_skin_texture(result_lit, original_array, mask_array)
        
        # Edge blending
        result_blended = self.blend_edges(result_textured, original_array, mask_array)
        
        return Image.fromarray(result_blended.astype(np.uint8))
    
    def match_skin_tone(self, result, original, mask, target_tone):
        """Match skin tone between generated and original areas"""
        # Extract skin areas from result
        skin_mask = mask > 0.1
        
        if np.any(skin_mask):
            # Get current skin tone in generated areas
            generated_skin = result[skin_mask]
            current_tone = np.mean(generated_skin, axis=0)
            
            # Calculate adjustment
            tone_diff = np.array(target_tone) - current_tone
            
            # Apply adjustment
            result_adjusted = result.copy()
            result_adjusted[skin_mask] = np.clip(
                result_adjusted[skin_mask] + tone_diff, 0, 255
            )
            
            return result_adjusted
        
        return result
    
    def apply_lighting_correction(self, image, lighting):
        """Apply lighting correction based on scene analysis"""
        # Simple lighting adjustment based on direction
        if lighting['direction'] == 'right':
            # Enhance right side, darken left side
            h, w = image.shape[:2]
            gradient = np.linspace(0.8, 1.2, w)
            gradient = gradient[np.newaxis, :, np.newaxis]
            image = image * gradient
        else:
            # Enhance left side, darken right side
            h, w = image.shape[:2]
            gradient = np.linspace(1.2, 0.8, w)
            gradient = gradient[np.newaxis, :, np.newaxis]
            image = image * gradient
        
        return np.clip(image, 0, 255)
    
    def enhance_skin_texture(self, result, original, mask):
        """Enhance skin texture to match original"""
        # Extract texture from original non-masked areas
        original_gray = cv2.cvtColor(original, cv2.COLOR_RGB2GRAY)
        result_gray = cv2.cvtColor(result.astype(np.uint8), cv2.COLOR_RGB2GRAY)
        
        # Apply subtle texture from original
        texture_strength = 0.3
        skin_mask = mask > 0.1
        
        if np.any(skin_mask):
            # Blend textures
            for c in range(3):
                result[skin_mask, c] = (
                    result[skin_mask, c] * (1 - texture_strength) +
                    original[skin_mask, c] * texture_strength
                )
        
        return result
    
    def blend_edges(self, result, original, mask):
        """Smooth blending at mask edges"""
        # Create soft edge mask
        mask_blur = cv2.GaussianBlur(mask, (21, 21), 0)
        mask_blur = mask_blur[:, :, np.newaxis]
        
        # Blend with soft edges
        blended = result * mask_blur + original * (1 - mask_blur)
        
        return blended

def main():
    """Test the perfect nude generator"""
    generator = PerfectNudeGenerator()
    
    # Test with the uploaded image
    input_path = "/home/ubuntu/nude_generator_project/data/input/sample_input.png"
    output_path = "/home/ubuntu/nude_generator_project/data/output/perfect_nude_result.png"
    mask_path = "/home/ubuntu/nude_generator_project/data/output/perfect_mask.png"
    
    try:
        result, mask = generator.generate_perfect_nude(
            input_path, 
            output_path,
            num_inference_steps=30  # Good balance of quality/speed
        )
        
        # Save mask for inspection
        mask.save(mask_path)
        
        print(f"âœ… Perfect nude generation completed!")
        print(f"ğŸ“ Result: {output_path}")
        print(f"ğŸ“ Mask: {mask_path}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        return False

if __name__ == "__main__":
    main()

